{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a2fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b1aa19e",
   "metadata": {},
   "source": [
    "# DeepSpeed的三个Stage详细介绍\n",
    "\n",
    "DeepSpeed是微软推出的用于大规模分布式训练的优化库，其核心技术之一是ZeRO（Zero Redundancy Optimizer）优化器。ZeRO采用了分层内存优化策略，将模型训练中的内存压力分散到多个GPU上。整体来说，DeepSpeed的ZeRO优化可以分为三个阶段，每个阶段在不同程度上降低内存占用，支持更大规模的模型训练。\n",
    "\n",
    "## Stage 1：优化器状态的分区\n",
    "- **核心思想**：将优化器相关状态（如**动量、第二矩估计**等）分布到各个GPU上，而不是在每个GPU上都存储一份完整的副本。\n",
    "- **适用场景**：当优化器状态内存占用较大时，通过分布存储可以有效减轻单个GPU的内存压力。\n",
    "\n",
    "## Stage 2：梯度的分区\n",
    "- **核心思想**：在Stage 1的基础上，进一步将反向传播过程中产生的**梯度**也进行分区存储，同样将其分散到不同的设备上。\n",
    "- **适用场景**：当模型较大且梯度存储是主要的内存负担时，采用梯度分区能够进一步释放资源。\n",
    "\n",
    "## Stage 3：模型参数的分区\n",
    "- **核心思想**：最激进的内存优化策略，不仅优化器状态和梯度进行分区，就连**模型权重**也会在各个GPU之间进行切分存储。\n",
    "- **挑战**：需要非常精细的通信和同步机制来保证模型参数的正确更新和梯度回传，技术实现上和调度上难度更高。\n",
    "- **适用场景**：当训练超大规模模型时，模型参数本身占用的内存成为主要瓶颈，此时Stage 3能提供最优的内存占用和扩展性。\n",
    "\n",
    "总体来说，这三个Stage构成了一个渐进式的内存优化方案，根据训练规模和硬件资源，用户可以选择合适的Stage来平衡内存占用与通信开销。DeepSpeed通过这些\n",
    "| 阶段       | 分片对象                   | 显存节省倍数 | 通信开销       | 适用场景                                                                 |\n",
    "|------------|----------------------------|--------------|----------------|--------------------------------------------------------------------------|\n",
    "| ​**Stage 1**​ | 优化器状态                 | 4-8 倍       | 与 DDP 相同 | 优化器状态占主导的中等规模模型（如 1.5B 参数）               |\n",
    "| ​**Stage 2**​ | 优化器状态 + 梯度          | 8-16 倍      | 与 DDP 相同 | 梯度显存较高的大模型（如 10B 参数），平衡显存与效率的首选方案 |\n",
    "| ​**Stage 3**​ | 优化器状态 + 梯度 + 参数   | 16-64 倍+    | 增加约 50% | 超大规模模型（如千亿参数级别），需高速网络支持或显存严重受限环境 |\n",
    "\n",
    "（Stage3 增加的通信量是模型在前向传播时同步模型参数时产生的）\n",
    "\n",
    "**Question：为什么需要一直保存每个参数的fp16格式的梯度值呢？每算出来一个梯度值就去更新优化器中fp32的权重不就可以释放了吗？**\n",
    "\n",
    "**Answer**：反向传播需要一次性计算所有参数的梯度​（通过链式法则逐层传递），无法逐参数单独更新。\n",
    "            如果每算出一个梯度就立刻更新FP32权重：1.​破坏计算图，PyTorch/TensorFlow等框架依赖全局计算图进行自动微分，中途更新参数会中断反向传播流程。2.​引入竞态条件​：并行计算时（如多GPU），异步更新可能导致参数不一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16bff56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
